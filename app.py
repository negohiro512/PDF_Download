import streamlit as st
import os
import time
import urllib.parse
import requests
import shutil
import tempfile
from bs4 import BeautifulSoup

# --- ç”»é¢ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆå¤‰æ›´ã—ã¾ã—ãŸï¼‰ ---
st.title("PDFä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼")
st.write("æŒ‡å®šã—ãŸURLã‹ã‚‰ã€æ¡ä»¶ã«åˆã†PDFã‚’ã¾ã¨ã‚ã¦ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚")

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›æ¬„ ---
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¯ç¦å²¡å¸‚ã®ä¾‹ã‚’å…¥ã‚Œã¦ã„ã¾ã™
default_url = "https://www.city.fukuoka.lg.jp/kankyo/sanhai/hp/sangyouhaikibutu/haisyutujigyousya/taryoukouhyou.html"
target_url = st.text_input("å¯¾è±¡ã®URL", default_url)
keyword = st.text_input("ãƒ•ã‚¡ã‚¤ãƒ«åã«å«ã‚€æ–‡å­— (ç©ºæ¬„ãªã‚‰ã™ã¹ã¦)", "06")

# --- å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
if st.button("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹"):
    # é€²æ—ãƒãƒ¼ã®è¡¨ç¤º
    progress_bar = st.progress(0)
    status_text = st.empty()

    # ä¸€æ™‚ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼ˆå‡¦ç†ãŒçµ‚ã‚ã£ãŸã‚‰è‡ªå‹•ã§æ¶ˆãˆã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼‰
    with tempfile.TemporaryDirectory() as temp_dir:
        save_dir = os.path.join(temp_dir, "pdfs")
        os.makedirs(save_dir, exist_ok=True)

        status_text.text("ã‚µã‚¤ãƒˆã®æƒ…å ±ã‚’å–å¾—ä¸­...")

        try:
            # ã€é‡è¦ã€‘ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã ã¨æ€ã‚ã›ã‚‹ãŸã‚ã®ã€Œååˆºã€ã®ã‚ˆã†ãªã‚‚ã®ï¼ˆUser-Agentï¼‰
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
            response = requests.get(target_url, headers=headers)
            response.raise_for_status() # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ã“ã“ã§æ­¢ã¾ã‚‹

            soup = BeautifulSoup(response.content, "html.parser")
            links = soup.find_all("a")

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ã®ãƒªã‚¹ãƒˆã‚’ä½œã‚‹
            download_targets = []
            for link in links:
                href = link.get("href")
                if href and href.lower().endswith(".pdf"):
                    # ã€é‡è¦ã€‘ç›¸å¯¾ãƒ‘ã‚¹ï¼ˆä¾‹: ../a.pdfï¼‰ã‚’çµ¶å¯¾ãƒ‘ã‚¹ï¼ˆhttp://.../a.pdfï¼‰ã«å¤‰æ›
                    full_url = urllib.parse.urljoin(target_url, href)
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—ï¼ˆURLã®æœ€å¾Œã®éƒ¨åˆ†ï¼‰
                    # æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åãªã©ãŒURLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã«å¯¾å¿œ
                    filename = os.path.basename(urllib.parse.urlparse(full_url).path)
                    try:
                        filename = urllib.parse.unquote(filename)
                    except:
                        pass # å¤‰æ›ã§ããªã‘ã‚Œã°ãã®ã¾ã¾
                    
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµã‚Šè¾¼ã¿
                    if not keyword or keyword in filename:
                        download_targets.append((filename, full_url))

            # é‡è¤‡ã‚’é™¤å»ï¼ˆåŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒªãƒ³ã‚¯ãŒè¤‡æ•°ã‚ã‚‹å ´åˆãªã©ï¼‰
            download_targets = list(set(download_targets))

            if not download_targets:
                status_text.warning(f"ã€Œ{keyword}ã€ã‚’å«ã‚€PDFã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\nï¼ˆå–å¾—ã§ããŸãƒªãƒ³ã‚¯æ•°: {len(links)}ä»¶ï¼‰")
                progress_bar.empty()
            else:
                status_text.text(f"{len(download_targets)} ä»¶ã®PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
                for i, (filename, url) in enumerate(download_targets):
                    try:
                        file_res = requests.get(url, headers=headers)
                        # ãƒ•ã‚¡ã‚¤ãƒ«åãŒè¢«ã‚‰ãªã„ã‚ˆã†ã«å·¥å¤«ã—ã¦ã‚‚è‰¯ã„ãŒã€ä»Šå›ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ä¿å­˜
                        file_path = os.path.join(save_dir, filename)
                        
                        with open(file_path, "wb") as f:
                            f.write(file_res.content)
                        
                        # é€²æ—ãƒãƒ¼æ›´æ–°
                        progress_bar.progress((i + 1) / len(download_targets))
                        time.sleep(0.1) # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ã®ãŸã‚å°‘ã—å¾…ã¤
                    except Exception as e:
                        st.write(f"ã‚¨ãƒ©ãƒ¼: {filename} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})")

                # ZIPã«åœ§ç¸®
                status_text.text("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­...")
                shutil.make_archive(os.path.join(temp_dir, "download_files"), 'zip', save_dir)
                zip_path = os.path.join(temp_dir, "download_files.zip")

                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                with open(zip_path, "rb") as f:
                    st.download_button(
                        label="ğŸ“¦ ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=f,
                        file_name="downloaded_pdfs.zip",
                        mime="application/zip"
                    )
                
                status_text.success("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼ä¸Šã®ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
